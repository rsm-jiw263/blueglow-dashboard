#!/usr/bin/env python3
"""
Step 3: Train lightweight Logistic Regression model
ä½¿ç”¨å¼±ç›‘ç£é“¶æ ‡è§„åˆ™ + æ°”å€™å­¦ç‰¹å¾è®­ç»ƒæ¨¡åž‹
"""

import os
import json
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
import joblib

ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
CLIM_FILE = os.path.join(ROOT, "data", "climatology.json")
MODEL_FILE = os.path.join(ROOT, "models", "biolum_lr.pkl")

def load_climatology():
    """åŠ è½½æ°”å€™å­¦æ•°æ®"""
    with open(CLIM_FILE, 'r') as f:
        return json.load(f)

def generate_weak_supervision_labels(n_samples=5000):
    """
    ç”Ÿæˆå¼±ç›‘ç£è®­ç»ƒæ ·æœ¬
    è§„åˆ™: æš—å¤œ + ä½Žæ½®Â±2h + ä½Žæµª â†’ é«˜å¯èƒ½ (label=1)
          å¦åˆ™ â†’ ä½Žå¯èƒ½ (label=0)
    """
    print(f"ðŸ·ï¸  Generating {n_samples} weak supervision samples...")
    
    # åŠ è½½æ°”å€™å­¦æ•°æ®
    clim = load_climatology()
    wave_doy = clim['wave_height_doy']
    temp_doy = clim['water_temp_doy']
    
    samples = []
    
    # éšæœºç”Ÿæˆæ—¶é—´ç‚¹ (è¿‡åŽ»ä¸€å¹´)
    base_date = datetime(2024, 1, 1)
    
    for _ in range(n_samples):
        # éšæœºæ—¥æœŸå’Œæ—¶é—´
        random_days = np.random.randint(0, 365)
        random_hour = np.random.randint(0, 24)
        dt = base_date + timedelta(days=random_days, hours=random_hour)
        
        doy = dt.timetuple().tm_yday
        hour = dt.hour
        
        # ç‰¹å¾1: æœˆç…§åº¦ (ç®€åŒ–è®¡ç®—: åŸºäºŽæœˆç›¸å‘¨æœŸ29.5å¤©)
        days_since_new_moon = (random_days % 29.5)
        moon_illum = 1.0 - abs(days_since_new_moon - 14.75) / 14.75
        moon_illum = max(0.0, min(1.0, moon_illum))
        
        # ç‰¹å¾2: æ˜¯å¦å¤œé—´ (18:00-06:00)
        is_night = (hour >= 18 or hour <= 6)
        
        # ç‰¹å¾3: æ½®æ±ç›¸ä½ (ç®€åŒ–: åŸºäºŽM2å‘¨æœŸ12.42å°æ—¶)
        hours_total = random_days * 24 + hour
        tide_phase = (hours_total / 12.42) * 2 * np.pi
        tide_level = np.cos(tide_phase)  # -1=ä½Žæ½®, 1=é«˜æ½®
        
        # ç‰¹å¾4: æµªé«˜æ°”å€™å€¼
        wave_height = float(wave_doy.get(str(doy), 1.0))
        
        # ç‰¹å¾5: æ°´æ¸©æ°”å€™å€¼
        water_temp = float(temp_doy.get(str(doy), 16.0))
        
        # ç‰¹å¾6: å­£èŠ‚ (å½’ä¸€åŒ–åˆ°0-1)
        season_norm = np.sin(2 * np.pi * doy / 365)
        
        # å¼±ç›‘ç£è§„åˆ™
        dark_night = (moon_illum < 0.3) and is_night
        low_tide = (tide_level < -0.5)  # ä½Žæ½®
        low_wave = (wave_height < 1.2)  # æµªé«˜ < 1.2m
        
        # é“¶æ ‡: æ»¡è¶³3ä¸ªæ¡ä»¶ â†’ é«˜å¯èƒ½
        label = 1 if (dark_night and low_tide and low_wave) else 0
        
        samples.append({
            'moon_illumination': moon_illum,
            'is_night': int(is_night),
            'tide_level': tide_level,
            'wave_height': wave_height,
            'water_temp': water_temp,
            'season_sin': season_norm,
            'label': label
        })
    
    df = pd.DataFrame(samples)
    
    print(f"   Positive samples (label=1): {df['label'].sum()} ({df['label'].mean()*100:.1f}%)")
    print(f"   Negative samples (label=0): {(1-df['label']).sum()}")
    
    return df

def train_model(df):
    """è®­ç»ƒé€»è¾‘å›žå½’æ¨¡åž‹"""
    print("\nðŸ¤– Training Logistic Regression model...")
    
    # ç‰¹å¾å’Œæ ‡ç­¾
    feature_cols = ['moon_illumination', 'is_night', 'tide_level', 
                    'wave_height', 'water_temp', 'season_sin']
    
    X = df[feature_cols].values
    y = df['label'].values
    
    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"   Train: {len(X_train)} samples, Test: {len(X_test)} samples")
    
    # è®­ç»ƒæ¨¡åž‹ (class_weight='balanced' å¤„ç†ç±»åˆ«ä¸å¹³è¡¡)
    model = LogisticRegression(
        class_weight='balanced',
        max_iter=1000,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    # è¯„ä¼°
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]
    
    print("\nðŸ“Š Model Performance:")
    print(classification_report(y_test, y_pred, target_names=['Low', 'High']))
    
    auc = roc_auc_score(y_test, y_prob)
    print(f"   ROC-AUC: {auc:.3f}")
    
    # ç‰¹å¾é‡è¦æ€§
    print("\nðŸ“ˆ Feature Importance (Coefficients):")
    for feat, coef in zip(feature_cols, model.coef_[0]):
        print(f"   {feat:20s}: {coef:+.3f}")
    
    return model, feature_cols

def save_model(model, feature_cols):
    """ä¿å­˜æ¨¡åž‹"""
    os.makedirs(os.path.dirname(MODEL_FILE), exist_ok=True)
    
    model_data = {
        'model': model,
        'feature_cols': feature_cols,
        'metadata': {
            'trained_at': datetime.utcnow().isoformat() + 'Z',
            'model_type': 'LogisticRegression',
            'features': feature_cols,
            'version': '1.0-climatology',
            'note': 'Trained with weak supervision. Ready for SST/Chl-a features when available.'
        }
    }
    
    joblib.dump(model_data, MODEL_FILE)
    print(f"\nâœ… Model saved: {MODEL_FILE}")
    print(f"   Size: {os.path.getsize(MODEL_FILE)} bytes")

def main():
    print("=" * 60)
    print("ï¿½ï¿½ BlueGlow - Step 3: Train Model")
    print("=" * 60)
    
    # 1. ç”Ÿæˆå¼±ç›‘ç£æ ·æœ¬
    df = generate_weak_supervision_labels(n_samples=5000)
    
    # 2. è®­ç»ƒæ¨¡åž‹
    model, feature_cols = train_model(df)
    
    # 3. ä¿å­˜æ¨¡åž‹
    save_model(model, feature_cols)
    
    print("\n" + "=" * 60)
    print("âœ… Training complete!")
    print("   Next: Run step4_forecast.sh to generate predictions")
    print("=" * 60)

if __name__ == "__main__":
    main()
