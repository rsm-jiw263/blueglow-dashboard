#!/usr/bin/env python3
"""
ä¸‹è½½La JollaçœŸå®ç¯å¢ƒæ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰
- è§£å†³NOAA 31å¤©é™åˆ¶ï¼ˆåˆ†æ‰¹ä¸‹è½½ï¼‰
- è§£å†³NDBC SSLè¯ä¹¦é—®é¢˜ï¼ˆç¦ç”¨éªŒè¯ï¼‰
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
import time
import sys
import urllib3
import ssl

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def download_noaa_chunked(product, output_file, station='9410230', 
                          begin_date='20240101', end_date='20241231'):
    """
    ä»NOAA APIä¸‹è½½æ•°æ®ï¼ˆåˆ†æ‰¹ä¸‹è½½é¿å…31å¤©é™åˆ¶ï¼‰
    
    å‚æ•°:
        product: 'water_temperature', 'wind', 'air_temperature', 'water_level'
        output_file: CSVæ–‡ä»¶ä¿å­˜è·¯å¾„
        station: ç«™ç‚¹ID (é»˜è®¤9410230 = La Jolla/Scripps Pier)
        begin_date/end_date: YYYYMMDDæ ¼å¼
    """
    base_url = 'https://api.tidesandcurrents.noaa.gov/api/prod/datagetter'
    
    start_dt = datetime.strptime(begin_date, '%Y%m%d')
    end_dt = datetime.strptime(end_date, '%Y%m%d')
    
    all_data = []
    current_dt = start_dt
    chunk_days = 30  # æ¯æ¬¡è¯·æ±‚30å¤©
    
    print(f"\nğŸ“¡ ä¸‹è½½ NOAA {product} æ•°æ®")
    print(f"   ç«™ç‚¹: {station}")
    print(f"   èŒƒå›´: {begin_date} â†’ {end_date}")
    print(f"   ç­–ç•¥: æ¯æ¬¡30å¤©åˆ†æ‰¹è¯·æ±‚")
    
    batch_num = 0
    while current_dt <= end_dt:
        batch_num += 1
        chunk_end = min(current_dt + timedelta(days=chunk_days), end_dt)
        
        chunk_begin = current_dt.strftime('%Y%m%d')
        chunk_end_str = chunk_end.strftime('%Y%m%d')
        
        params = {
            'begin_date': chunk_begin,
            'end_date': chunk_end_str,
            'station': station,
            'product': product,
            'datum': 'MLLW',
            'time_zone': 'GMT',
            'units': 'metric',
            'format': 'json',
            'application': 'MGTA452_BlueGlow_Project'
        }
        
        print(f"   æ‰¹æ¬¡{batch_num}: {chunk_begin} â†’ {chunk_end_str} ... ", end="", flush=True)
        
        try:
            response = requests.get(base_url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            if 'error' in data:
                print(f"âš ï¸ {data['error'].get('message', 'APIé”™è¯¯')}")
                current_dt = chunk_end + timedelta(days=1)
                continue
            
            if 'data' in data and len(data['data']) > 0:
                all_data.extend(data['data'])
                print(f"âœ“ {len(data['data'])}æ¡")
            else:
                print("âš ï¸ æ— æ•°æ®")
            
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
        except requests.exceptions.HTTPError as e:
            print(f"âŒ HTTP {response.status_code}")
            if response.status_code == 400:
                print(f"      å¯èƒ½åŸå› : è¯¥ç«™ç‚¹ä¸æä¾› {product} æ•°æ®")
        except Exception as e:
            print(f"âŒ {type(e).__name__}: {str(e)[:50]}")
        
        current_dt = chunk_end + timedelta(days=1)
    
    # ä¿å­˜æ•°æ®
    if len(all_data) > 0:
        df = pd.DataFrame(all_data)
        df.to_csv(output_file, index=False)
        print(f"   âœ… æ€»å…± {len(df)} æ¡è®°å½• â†’ {output_file}\n")
        return True
    else:
        print(f"   âŒ æœªè·å–ä»»ä½•æ•°æ®\n")
        return False


def download_ndbc_buoy(buoy_id='46254', year='2024', output_file=None):
    """
    ä»NDBCä¸‹è½½æµ®æ ‡æ•°æ®ï¼ˆç¦ç”¨SSLéªŒè¯ï¼‰
    
    å‚æ•°:
        buoy_id: æµ®æ ‡ID (46254 = SCRIPPS Nearshore)
        year: å¹´ä»½
        output_file: CSVä¿å­˜è·¯å¾„
    """
    # NDBCæ ‡å‡†æ°”è±¡æ•°æ®æ–‡ä»¶æ ¼å¼
    url = f'https://www.ndbc.noaa.gov/view_text_file.php?filename={buoy_id}h{year}.txt.gz&dir=data/historical/stdmet/'
    
    print(f"\nğŸŒŠ ä¸‹è½½ NDBC æµ®æ ‡ {buoy_id} æ•°æ®")
    print(f"   å¹´ä»½: {year}")
    print(f"   URL: {url}")
    
    try:
        # ç¦ç”¨SSLè¯ä¹¦éªŒè¯
        response = requests.get(url, timeout=60, verify=False)
        response.raise_for_status()
        
        # NDBCæ–‡ä»¶æ˜¯æ–‡æœ¬æ ¼å¼ï¼Œéœ€è¦è§£æ
        lines = response.text.strip().split('\n')
        
        if len(lines) < 3:
            print(f"   âŒ æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®\n")
            return False
        
        # ç¬¬ä¸€è¡Œæ˜¯åˆ—åï¼Œç¬¬äºŒè¡Œæ˜¯å•ä½ï¼Œç¬¬ä¸‰è¡Œå¼€å§‹æ˜¯æ•°æ®
        header = lines[0].split()
        units = lines[1].split()
        data_lines = lines[2:]
        
        # è§£ææ•°æ®
        data_rows = []
        for line in data_lines:
            parts = line.split()
            if len(parts) >= len(header):
                data_rows.append(parts[:len(header)])
        
        if len(data_rows) == 0:
            print(f"   âŒ æ— æœ‰æ•ˆæ•°æ®è¡Œ\n")
            return False
        
        df = pd.DataFrame(data_rows, columns=header)
        
        if output_file:
            df.to_csv(output_file, index=False)
            print(f"   âœ… {len(df)} æ¡è®°å½• â†’ {output_file}\n")
        
        return True
        
    except requests.exceptions.SSLError as e:
        print(f"   âŒ SSLè¯ä¹¦é”™è¯¯ï¼ˆå·²å°è¯•ç¦ç”¨éªŒè¯ï¼‰: {str(e)[:80]}\n")
        return False
    except Exception as e:
        print(f"   âŒ {type(e).__name__}: {str(e)[:80]}\n")
        return False


def main():
    """ä¸»ä¸‹è½½æµç¨‹"""
    print("=" * 60)
    print("ğŸŒŠ La Jolla è“çœ¼æ³ªé¡¹ç›® - çœŸå®ç¯å¢ƒæ•°æ®ä¸‹è½½")
    print("=" * 60)
    
    success_count = 0
    total_count = 0
    
    # 1. NOAAæ°´æ¸©æ•°æ®
    total_count += 1
    if download_noaa_chunked(
        product='water_temperature',
        output_file='data/water_temp_lajolla.csv',
        station='9410230',
        begin_date='20240101',
        end_date='20241231'
    ):
        success_count += 1
    
    # 2. NOAAé£é€Ÿæ•°æ®
    total_count += 1
    if download_noaa_chunked(
        product='wind',
        output_file='data/wind_lajolla.csv',
        station='9410230',
        begin_date='20240101',
        end_date='20241231'
    ):
        success_count += 1
    
    # 3. NOAAæ°”æ¸©æ•°æ®ï¼ˆé¢å¤–å°è¯•ï¼‰
    total_count += 1
    if download_noaa_chunked(
        product='air_temperature',
        output_file='data/air_temp_lajolla.csv',
        station='9410230',
        begin_date='20240101',
        end_date='20241231'
    ):
        success_count += 1
    
    # 4. NDBCæµ®æ ‡æµªé«˜æ•°æ®
    total_count += 1
    if download_ndbc_buoy(
        buoy_id='46254',
        year='2024',
        output_file='data/waves_lajolla.csv'
    ):
        success_count += 1
    
    # æ€»ç»“
    print("=" * 60)
    print(f"ğŸ“Š ä¸‹è½½å®Œæˆ: {success_count}/{total_count} ä¸ªæ•°æ®æºæˆåŠŸ")
    print("=" * 60)
    
    if success_count > 0:
        print("\nâœ… å·²ä¸‹è½½çš„æ–‡ä»¶:")
        import os
        for fname in ['water_temp_lajolla.csv', 'wind_lajolla.csv', 
                      'air_temp_lajolla.csv', 'waves_lajolla.csv']:
            fpath = f'data/{fname}'
            if os.path.exists(fpath):
                size = os.path.getsize(fpath)
                print(f"   â€¢ {fpath} ({size:,} bytes)")
    
    if success_count == 0:
        print("\nâš ï¸  æ‰€æœ‰æ•°æ®æºå‡ä¸‹è½½å¤±è´¥")
        print("\nğŸ”§ æ›¿ä»£æ–¹æ¡ˆ:")
        print("   1. æ‰‹åŠ¨ä¸‹è½½NOAAæ•°æ®:")
        print("      https://tidesandcurrents.noaa.gov/waterlevels.html?id=9410230")
        print("   2. æ‰‹åŠ¨ä¸‹è½½NDBCæ•°æ®:")
        print("      https://www.ndbc.noaa.gov/station_page.php?station=46254")
        print("   3. ä½¿ç”¨ç¬”è®°æœ¬ä¸­çš„demoæ•°æ®ï¼ˆè‡ªåŠ¨fallbackï¼‰")
        print("\nè¯¦ç»†è¯´æ˜è§: data/README_DATA_ACQUISITION.md")
    
    return success_count


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success > 0 else 1)
