#!/usr/bin/env python3
"""
Step 2 æ•°æ®éªŒæ”¶è„šæœ¬
å¿«é€Ÿæ£€æŸ¥ä¸‹è½½çš„ NetCDF å’Œ CSV æ–‡ä»¶è´¨é‡
"""

import glob
import os

def check_netcdf():
    """æ£€æŸ¥ NetCDF (SST/Chl-a) æ–‡ä»¶"""
    print("=" * 60)
    print("ğŸ“Š æ£€æŸ¥ NetCDF æ–‡ä»¶ (SST & Chl-a)")
    print("=" * 60)
    
    try:
        import xarray as xr
        
        # Check SST files
        sst_files = sorted(glob.glob('data/raw/sst_*.nc'))
        print(f"\nâœ… SST æ–‡ä»¶æ•°é‡: {len(sst_files)}")
        
        if sst_files:
            print(f"\nğŸ“ SST æ–‡ä»¶åˆ—è¡¨:")
            for f in sst_files:
                size_mb = os.path.getsize(f) / 1024 / 1024
                print(f"  - {os.path.basename(f)}: {size_mb:.2f} MB")
            
            print(f"\nğŸ” SST æ ·æœ¬æ£€æŸ¥ ({os.path.basename(sst_files[0])}):")
            ds = xr.open_dataset(sst_files[0])
            print(f"  ç»´åº¦: {dict(ds.dims)}")
            print(f"  æ—¶é—´èŒƒå›´: {str(ds.time.values.min())[:19]} â†’ {str(ds.time.values.max())[:19]}")
            print(f"  çº¬åº¦èŒƒå›´: {float(ds.latitude.values.min()):.4f} â†’ {float(ds.latitude.values.max()):.4f}")
            print(f"  ç»åº¦èŒƒå›´: {float(ds.longitude.values.min()):.4f} â†’ {float(ds.longitude.values.max()):.4f}")
            print(f"  å˜é‡: {list(ds.data_vars.keys())}")
            
            # Check for missing values
            if 'sst' in ds:
                sst_data = ds.sst.values
                import numpy as np
                valid_pct = (1 - np.isnan(sst_data).sum() / sst_data.size) * 100
                print(f"  æ•°æ®å®Œæ•´åº¦: {valid_pct:.1f}%")
            
            ds.close()
        else:
            print("âš ï¸  æœªæ‰¾åˆ° SST æ–‡ä»¶")
        
        # Check Chl-a files
        chla_files = sorted(glob.glob('data/raw/chla_*.nc'))
        print(f"\nâœ… Chl-a æ–‡ä»¶æ•°é‡: {len(chla_files)}")
        
        if chla_files:
            print(f"\nğŸ“ Chl-a æ–‡ä»¶åˆ—è¡¨:")
            for f in chla_files:
                size_mb = os.path.getsize(f) / 1024 / 1024
                print(f"  - {os.path.basename(f)}: {size_mb:.2f} MB")
            
            print(f"\nğŸ” Chl-a æ ·æœ¬æ£€æŸ¥ ({os.path.basename(chla_files[0])}):")
            dc = xr.open_dataset(chla_files[0])
            print(f"  ç»´åº¦: {dict(dc.dims)}")
            print(f"  æ—¶é—´èŒƒå›´: {str(dc.time.values.min())[:19]} â†’ {str(dc.time.values.max())[:19]}")
            print(f"  çº¬åº¦èŒƒå›´: {float(dc.latitude.values.min()):.4f} â†’ {float(dc.latitude.values.max()):.4f}")
            print(f"  ç»åº¦èŒƒå›´: {float(dc.longitude.values.min()):.4f} â†’ {float(dc.longitude.values.max()):.4f}")
            print(f"  å˜é‡: {list(dc.data_vars.keys())}")
            dc.close()
        else:
            print("âš ï¸  æœªæ‰¾åˆ° Chl-a æ–‡ä»¶")
            
    except ImportError:
        print("âŒ xarray æœªå®‰è£…,æ— æ³•æ£€æŸ¥ NetCDF æ–‡ä»¶")
    except Exception as e:
        print(f"âŒ NetCDF æ£€æŸ¥å‡ºé”™: {e}")

def check_ndbc():
    """æ£€æŸ¥ NDBC CSV æ–‡ä»¶"""
    print("\n" + "=" * 60)
    print("ğŸ’¨ æ£€æŸ¥ NDBC é£é€Ÿæ•°æ®")
    print("=" * 60)
    
    try:
        import pandas as pd
        
        ndbc_files = sorted(glob.glob('data/raw/ndbc_46254_*.csv'))
        
        if not ndbc_files:
            print("âš ï¸  æœªæ‰¾åˆ° NDBC æ–‡ä»¶")
            return
        
        print(f"\nâœ… NDBC æ–‡ä»¶æ•°é‡: {len(ndbc_files)}")
        
        for f in ndbc_files:
            size_mb = os.path.getsize(f) / 1024 / 1024
            print(f"\nğŸ“ æ–‡ä»¶: {os.path.basename(f)} ({size_mb:.2f} MB)")
            
            df = pd.read_csv(f)
            print(f"  æ€»è¡Œæ•°: {len(df):,}")
            print(f"  åˆ—æ•°: {len(df.columns)}")
            print(f"  åˆ—å: {list(df.columns[:10])}...")
            
            if 'dt' in df.columns:
                df['dt'] = pd.to_datetime(df['dt'])
                print(f"  æ—¶é—´èŒƒå›´: {df['dt'].min()} â†’ {df['dt'].max()}")
            
            if 'WSPD' in df.columns:
                df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')
                valid_wspd = df['WSPD'][df['WSPD'] < 90].dropna()
                if len(valid_wspd) > 0:
                    print(f"  é£é€Ÿç»Ÿè®¡ (m/s):")
                    print(f"    - å¹³å‡: {valid_wspd.mean():.2f}")
                    print(f"    - èŒƒå›´: {valid_wspd.min():.2f} â†’ {valid_wspd.max():.2f}")
                    print(f"    - æœ‰æ•ˆæ•°æ®ç‚¹: {len(valid_wspd):,} ({len(valid_wspd)/len(df)*100:.1f}%)")
            
            print(f"\n  æ ·æœ¬æ•°æ® (å‰5è¡Œ):")
            print(df[['dt', 'WSPD', 'WDIR']].head().to_string(index=False) if 'dt' in df.columns and 'WSPD' in df.columns else df.head())
            
    except ImportError:
        print("âŒ pandas æœªå®‰è£…,æ— æ³•æ£€æŸ¥ CSV æ–‡ä»¶")
    except Exception as e:
        print(f"âŒ NDBC æ£€æŸ¥å‡ºé”™: {e}")

def check_summary():
    """æ€»ä½“æ‘˜è¦"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®ä¸‹è½½æ€»ç»“")
    print("=" * 60)
    
    sst_count = len(glob.glob('data/raw/sst_*.nc'))
    chla_count = len(glob.glob('data/raw/chla_*.nc'))
    ndbc_count = len(glob.glob('data/raw/ndbc_*.csv'))
    
    # Calculate total size
    all_files = glob.glob('data/raw/*')
    total_size = sum(os.path.getsize(f) for f in all_files if os.path.isfile(f))
    total_size_mb = total_size / 1024 / 1024
    
    print(f"\næ–‡ä»¶ç»Ÿè®¡:")
    print(f"  âœ… SST (NetCDF): {sst_count} ä¸ªæ–‡ä»¶")
    print(f"  âœ… Chl-a (NetCDF): {chla_count} ä¸ªæ–‡ä»¶")
    print(f"  âœ… NDBC (CSV): {ndbc_count} ä¸ªæ–‡ä»¶")
    print(f"  ğŸ“¦ æ€»å¤§å°: {total_size_mb:.2f} MB")
    
    # Expected files (23 months from 2024-01 to 2025-11)
    expected_months = 23
    print(f"\né¢„æœŸæœˆä»½æ•°: {expected_months}")
    
    if sst_count == expected_months and chla_count == expected_months:
        print("âœ… æ•°æ®å®Œæ•´!")
    else:
        print(f"âš ï¸  å¯èƒ½ç¼ºå°‘éƒ¨åˆ†æœˆä»½æ•°æ®")
        if sst_count < expected_months:
            print(f"   - SST ç¼ºå°‘ {expected_months - sst_count} ä¸ªæœˆ")
        if chla_count < expected_months:
            print(f"   - Chl-a ç¼ºå°‘ {expected_months - chla_count} ä¸ªæœˆ")
    
    print("\n" + "=" * 60)
    print("éªŒæ”¶å®Œæˆ! å¯ä»¥ç»§ç»­ Step 3 è®­ç»ƒæ¨¡å‹")
    print("=" * 60)

def main():
    print("\nğŸŒŠ BlueGlow Step 2 - æ•°æ®éªŒæ”¶\n")
    
    if not os.path.exists('data/raw'):
        print("âŒ data/raw ç›®å½•ä¸å­˜åœ¨,è¯·å…ˆè¿è¡Œ step2_fetch_data.sh")
        return
    
    check_netcdf()
    check_ndbc()
    check_summary()

if __name__ == "__main__":
    main()
